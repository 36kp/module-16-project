{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utils.fetcher_utils as fetcher\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import export_text, plot_tree\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pandas options\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the data \n",
    "imdb_df = fetcher.aquireIMDbDataFrame()\n",
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that are not useful for the model\n",
    "drop_columns = ['movie_imdb_link']\n",
    "imdb_df_filtered = imdb_df.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing values\n",
    "imdb_df_filtered = imdb_df.dropna(subset='title_year')\n",
    "imdb_df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code processes a DataFrame (imdb_df_filtered) to transform the 'genres' column,\n",
    "# which contains pipe-separated genre strings, into a one-hot encoded format. \n",
    "# The 'genres' column is first converted to a string type and split into lists of individual genres.\n",
    "# These lists are then exploded into multiple rows, with each genre represented separately.\n",
    "# One-hot encoding is applied to create binary columns for each unique genre.\n",
    "# Finally, the rows are grouped back by their original indices, and the one-hot encoded columns\n",
    "# are aggregated to ensure all genres for a single movie are captured in one row.\n",
    "# The transformed genre columns are concatenated with the rest of the original DataFrame\n",
    "# (excluding the original 'genres' column), resulting in a new DataFrame where each genre\n",
    "# is represented as a binary column (1 for presence, 0 for absence).\n",
    "\n",
    "genres = imdb_df_filtered\n",
    "genres['genres'] = genres['genres'].astype(str)\n",
    "genres['genres'] = genres['genres'].str.split('|')\n",
    "genre_dummies = genres['genres'].explode().str.get_dummies().groupby(level=0).max()\n",
    "# columns = genre_dummies.columns.tolist()\n",
    "# columns\n",
    "imdb_df_filtered = pd.concat([genres.drop(columns=['genres']), genre_dummies], axis=1)\n",
    "imdb_df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "director_dummies = imdb_df_filtered['director_name'].str.get_dummies()\n",
    "director_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code performs one-hot encoding on the 'content_rating' column of the \n",
    "# DataFrame (imdb_df_filtered). Each unique value in the 'content_rating' \n",
    "# column is transformed into a separate binary column, where:\n",
    "#   - A value of 1 indicates the presence of that specific content rating for the row.\n",
    "#   - A value of 0 indicates its absence.\n",
    "# \n",
    "# The one-hot encoded binary columns are stored in the `content_rating` DataFrame. \n",
    "# These columns are then concatenated with the original `imdb_df_filtered` DataFrame, \n",
    "# effectively adding the one-hot encoded columns to the existing data. \n",
    "\n",
    "\n",
    "content_rating = imdb_df_filtered['content_rating'].str.get_dummies()\n",
    "imdb_df_filtered = pd.concat([imdb_df_filtered, content_rating], axis=1)\n",
    "imdb_df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code calculates the experience of each director based on the number of movies \n",
    "# they have directed in the DataFrame (imdb_df_filtered). It performs the following steps:\n",
    "# 1. Groups the DataFrame by the 'director_name' column and counts the occurrences \n",
    "#    of each director, representing their total number of directed movies.\n",
    "#    The result is stored in `director_experience`, where the index is the director's name \n",
    "#    and the value is their movie count.\n",
    "# 2. Maps the `director_experience` values back to the `imdb_df_filtered` DataFrame \n",
    "#    by assigning the corresponding movie count (experience) to a new column, \n",
    "#    `director_experience`, for each director in the dataset.\n",
    "# \n",
    "# This process adds a new column, 'director_experience', that quantifies the number \n",
    "# of movies each director has directed, providing useful information for further analysis.\n",
    "\n",
    "\n",
    "director_experience = imdb_df_filtered.groupby('director_name')['director_name'].count()\n",
    "director_experience.head(10)\n",
    "imdb_df_filtered['director_experience'] = imdb_df_filtered['director_name'].map(director_experience)\n",
    "imdb_df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all non-numeric columns\n",
    "imdb_df_filtered = imdb_df_filtered.select_dtypes(include=['number'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = imdb_df_filtered.drop(columns=['imdb_score'])\n",
    "y = imdb_df_filtered['imdb_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Regressor model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using Mean Squared Error and R-squared\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot feature importance\n",
    "importance = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "plt.barh(feature_names, importance)\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Feature Importance in Predicting IMDb Score\")\n",
    "plt.yticks(fontsize=6)\n",
    "plt.figure(figsize=(8, 10))  \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual vs. Predicted (Training vs. Testing)\n",
    "\n",
    "# This graph compares actual values (y) to predicted values (y_pred) for both training and testing data. \n",
    "# It shows how well the model performs on the data it has seen (training) versus unseen data (testing).\n",
    "    \n",
    "plt.scatter(y_train, y_train_pred, label=\"Train Data\", alpha=0.7)\n",
    "plt.scatter(y_test, y_test_pred, label=\"Test Data\", alpha=0.7)\n",
    "plt.plot([min(y_train), max(y_train)], [min(y_train), max(y_train)], color='red', linestyle='--')\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs. Predicted (Training & Testing)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Plot\n",
    "# Residuals are the differences between actual values and predicted values. \n",
    "# A residual plot helps identify patterns and potential issues in the model.\n",
    "\n",
    "train_residuals = y_train - y_train_pred\n",
    "test_residuals = y_test - y_test_pred\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Training residuals\n",
    "plt.scatter(y_train_pred, train_residuals, label=\"Train Residuals\", alpha=0.7)\n",
    "# Testing residuals\n",
    "plt.scatter(y_test_pred, test_residuals, label=\"Test Residuals\", alpha=0.7)\n",
    "\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot (Training & Testing)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Distribution (Training vs. Testing)\n",
    "# The distribution of prediction errors (residuals) can indicate whether the model is biased or has issues with variance.\n",
    "\n",
    "# Plot Error Distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Training residuals\n",
    "plt.hist(train_residuals, bins=15, alpha=0.7, label=\"Train Residuals\")\n",
    "# Testing residuals\n",
    "plt.hist(test_residuals, bins=15, alpha=0.7, label=\"Test Residuals\")\n",
    "\n",
    "plt.xlabel(\"Prediction Error (Residuals)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Error Distribution (Training & Testing)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
