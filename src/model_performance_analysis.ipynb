{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import utils.pipeline_util as pipe\n",
    "import utils.transformer_util as tu\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV into a DataFrame\n",
    "imdb_df = pd.read_csv('../resources/movie_metadata.csv')\n",
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.info()\n",
    "imdb_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame with numeric columns\n",
    "imdb_df_numeric = imdb_df.select_dtypes(include='number')\n",
    "\n",
    "# Find correlation between numeric columns with imdb_score\n",
    "correlation = imdb_df_numeric.corr()['imdb_score'].sort_values(ascending=False)\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot model scores\n",
    "def plot_model_scores(data: pd.DataFrame, title='Model Comparison'):\n",
    "    models = {\n",
    "            \"Linear Regression\": LinearRegression(),\n",
    "            \"Lasso Regression\": Lasso(),\n",
    "            \"Ridge Regression\": Ridge(),\n",
    "            \"Support Vector Machine\": SVR(),\n",
    "            \"Random Forest\": RandomForestRegressor(n_estimators=128),\n",
    "            \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=128)\n",
    "        }\n",
    "\n",
    "    X = data.drop(columns=['imdb_score'])\n",
    "    y = data['imdb_score']\n",
    "\n",
    "    scores = []\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)   # 80% training and 20% test\n",
    "\n",
    "    for keys, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred, metrics = pipe.check_metrics(X_test, y_test, model)\n",
    "        metrics['model'] = keys\n",
    "        scores.append(metrics)\n",
    "        scores_df = pd.DataFrame(scores)\n",
    "    \n",
    "    display(scores_df)\n",
    "    # Plot Line chart for the models with all columns in the DataFrame\n",
    "    ax = scores_df.plot(\n",
    "        x='model',\n",
    "        y=['Mean Squared Error', 'Adjusted R-squared'],\n",
    "        kind='line',\n",
    "        figsize=(10, 6),\n",
    "        title=title,\n",
    "        rot=45,\n",
    "        grid=True,\n",
    "        legend=True,\n",
    "        marker='o'\n",
    "    )\n",
    "\n",
    "    # Add annotations for each data point\n",
    "    for line in ax.get_lines():\n",
    "        y_data = line.get_ydata()  # Get y-data for the line\n",
    "        x_data = line.get_xdata()  # Get x-data for the line\n",
    "        for x, y in zip(x_data, y_data):\n",
    "            ax.annotate(f'{y:.2f}', xy=(x, y), xytext=(0, 5), textcoords='offset points', ha='center', va='bottom')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = imdb_df_numeric.isnull().sum().sort_values(ascending=False)\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values and check the shape of the data frame\n",
    "imdb_df_numeric = imdb_df_numeric.dropna()\n",
    "imdb_df_numeric.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model scores using imdb_df_numeric\n",
    "plot_model_scores(imdb_df_numeric, title='Model Comparison with Numeric Columns (No Scaling/Encoding)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run preprocessed data through pipeline\n",
    "# Plot the model scores using preprocessed_df\n",
    "model, best_y_pred, preprocessed_df = pipe.run_pipeline(data=imdb_df, use_PCA=False, debug=False)\n",
    "preprocessed_df = tu.encode_data(preprocessed_df)\n",
    "plot_model_scores(preprocessed_df, title='Model Comparison with Preprocessed Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for PCA\n",
    "X = imdb_df_numeric.drop(columns=['imdb_score'])\n",
    "y = imdb_df_numeric['imdb_score']\n",
    "\n",
    "# create train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PCA object with 3 components and check the explained variance\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "# Fit PCA on training data\n",
    "pca.fit(X_train)\n",
    "\n",
    "# Transform training and test data\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Create a DataFrame with PCA data\n",
    "X_train_pca_df = pd.DataFrame(X_train_pca, columns=['PCA1', 'PCA2', 'PCA3'])\n",
    "X_test_pca_df = pd.DataFrame(X_test_pca, columns=['PCA1', 'PCA2', 'PCA3'])\n",
    "\n",
    "# Check the explained variance\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation between PCA components and imdb_score\n",
    "X_train_pca_df['imdb_score'] = y_train.values # Add imdb_score to PCA data frame\n",
    "X_test_pca_df['imdb_score'] = y_test.values # Add imdb_score to PCA data frame\n",
    "\n",
    "correlation_pca = X_train_pca_df.corr()['imdb_score'].sort_values(ascending=False)\n",
    "correlation_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a chart showing correlation between PCA components with imdb_score not including the imdb_score column\n",
    "correlation_pca.drop('imdb_score').plot(kind='bar', figsize=(10, 6), title='Correlation between PCA components and imdb_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check PCA components weights for each feature\n",
    "pca_components = pd.DataFrame(pca.components_, columns=X.columns)\n",
    "pca_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_scores(X_train_pca_df, title='Model Comparison with PCA Data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
