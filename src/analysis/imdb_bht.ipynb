{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utils.fetcher_utils as fetcher\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import export_text, plot_tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pandas options\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the data \n",
    "df = fetcher.aquireIMDbDataFrame(\"../../resources\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that are not useful for the model\n",
    "drop_columns = ['movie_imdb_link']\n",
    "df_filtered = df.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing values\n",
    "df_filtered = df_filtered.dropna(subset='title_year')\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code processes a DataFrame (imdb_df_filtered) to transform the 'genres' column,\n",
    "# which contains pipe-separated genre strings, into a one-hot encoded format. \n",
    "# The 'genres' column is first converted to a string type and split into lists of individual genres.\n",
    "# These lists are then exploded into multiple rows, with each genre represented separately.\n",
    "# One-hot encoding is applied to create binary columns for each unique genre.\n",
    "# Finally, the rows are grouped back by their original indices, and the one-hot encoded columns\n",
    "# are aggregated to ensure all genres for a single movie are captured in one row.\n",
    "# The transformed genre columns are concatenated with the rest of the original DataFrame\n",
    "# (excluding the original 'genres' column), resulting in a new DataFrame where each genre\n",
    "# is represented as a binary column (1 for presence, 0 for absence).\n",
    "\n",
    "genres = df_filtered\n",
    "genres['genres'] = genres['genres'].astype(str)\n",
    "genres['genres'] = genres['genres'].str.split('|')\n",
    "genre_dummies = genres['genres'].explode().str.get_dummies().groupby(level=0).max()\n",
    "# columns = genre_dummies.columns.tolist()\n",
    "# columns\n",
    "df_filtered = pd.concat([genres.drop(columns=['genres']), genre_dummies], axis=1)\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "director_dummies = df_filtered['director_name'].str.get_dummies()\n",
    "director_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code performs one-hot encoding on the 'content_rating' column of the \n",
    "# DataFrame (imdb_df_filtered). Each unique value in the 'content_rating' \n",
    "# column is transformed into a separate binary column, where:\n",
    "#   - A value of 1 indicates the presence of that specific content rating for the row.\n",
    "#   - A value of 0 indicates its absence.\n",
    "# \n",
    "# The one-hot encoded binary columns are stored in the `content_rating` DataFrame. \n",
    "# These columns are then concatenated with the original `imdb_df_filtered` DataFrame, \n",
    "# effectively adding the one-hot encoded columns to the existing data. \n",
    "\n",
    "\n",
    "content_rating = df_filtered['content_rating'].str.get_dummies()\n",
    "df_filtered = pd.concat([df_filtered, content_rating], axis=1)\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code calculates the experience of each director based on the number of movies \n",
    "# they have directed in the DataFrame (imdb_df_filtered). It performs the following steps:\n",
    "# 1. Groups the DataFrame by the 'director_name' column and counts the occurrences \n",
    "#    of each director, representing their total number of directed movies.\n",
    "#    The result is stored in `director_experience`, where the index is the director's name \n",
    "#    and the value is their movie count.\n",
    "# 2. Maps the `director_experience` values back to the `imdb_df_filtered` DataFrame \n",
    "#    by assigning the corresponding movie count (experience) to a new column, \n",
    "#    `director_experience`, for each director in the dataset.\n",
    "# \n",
    "# This process adds a new column, 'director_experience', that quantifies the number \n",
    "# of movies each director has directed, providing useful information for further analysis.\n",
    "\n",
    "\n",
    "director_experience = df_filtered.groupby('director_name')['director_name'].count()\n",
    "director_experience.head(10)\n",
    "df_filtered['director_experience'] = df_filtered['director_name'].map(director_experience)\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all non-numeric columns\n",
    "df_filtered = df_filtered.select_dtypes(include=['number'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = df_filtered.drop(columns=['imdb_score'])\n",
    "y = df_filtered['imdb_score']\n",
    "\n",
    "df_filtered = StandardScaler().fit_transform(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Regressor model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using Mean Squared Error and R-squared\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot feature importance\n",
    "importance = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "plt.barh(feature_names, importance)\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Feature Importance in Predicting IMDb Score\")\n",
    "plt.yticks(fontsize=6)\n",
    "plt.figure(figsize=(8, 10))  \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual vs. Predicted (Training vs. Testing)\n",
    "\n",
    "# This graph compares actual values (y) to predicted values (y_pred) for both training and testing data. \n",
    "# It shows how well the model performs on the data it has seen (training) versus unseen data (testing).\n",
    "    \n",
    "plt.scatter(y_train, y_train_pred, label=\"Train Data\", alpha=0.7)\n",
    "plt.scatter(y_test, y_test_pred, label=\"Test Data\", alpha=0.7)\n",
    "plt.plot([min(y_train), max(y_train)], [min(y_train), max(y_train)], color='red', linestyle='--')\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs. Predicted (Training & Testing)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Plot\n",
    "# Residuals are the differences between actual values and predicted values. \n",
    "# A residual plot helps identify patterns and potential issues in the model.\n",
    "\n",
    "train_residuals = y_train - y_train_pred\n",
    "test_residuals = y_test - y_test_pred\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Training residuals\n",
    "plt.scatter(y_train_pred, train_residuals, label=\"Train Residuals\", alpha=0.7)\n",
    "# Testing residuals\n",
    "plt.scatter(y_test_pred, test_residuals, label=\"Test Residuals\", alpha=0.7)\n",
    "\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot (Training & Testing)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Distribution (Training vs. Testing)\n",
    "# The distribution of prediction errors (residuals) can indicate whether the model is biased or has issues with variance.\n",
    "\n",
    "# Plot Error Distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Training residuals\n",
    "plt.hist(train_residuals, bins=15, alpha=0.7, label=\"Train Residuals\")\n",
    "# Testing residuals\n",
    "plt.hist(test_residuals, bins=15, alpha=0.7, label=\"Test Residuals\")\n",
    "\n",
    "plt.xlabel(\"Prediction Error (Residuals)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Error Distribution (Training & Testing)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\n",
    "    'num_critic_for_reviews' : [1000],\n",
    "    'num_critic_for_reviews' : [2220],\n",
    "    'duration' : [120],\n",
    "    'director_facebook_likes' : [234],\n",
    "    'actor_3_facebook_likes' : [324243], \n",
    "    'actor_1_facebook_likes' : [2000],\n",
    "    'gross' : [21341234],\n",
    "    'num_voted_users' : [0],\n",
    "    'cast_total_facebook_likes' : [1234],\n",
    "    'facenumber_in_poster' : [0],\n",
    "    'num_user_for_reviews' : [0],\n",
    "    'budget' : [1234],\n",
    "    'title_year' : [2000],\n",
    "    'actor_2_facebook_likes' : [0], \n",
    "    'aspect_ratio' : [0], \n",
    "    'movie_facebook_likes' : [100000],\n",
    "    'Action' : [1],\n",
    "    'Adventure' : [0],\n",
    "    'Animation' : [0],\n",
    "    'Biography' : [0], \n",
    "    'Comedy' : [0],\n",
    "    'Crime' : [0],\n",
    "    'Documentary' : [0], \n",
    "    'Drama' : [0],\n",
    "    'Family' : [1],\n",
    "    'Fantasy' : [1],\n",
    "    'Film-Noir' : [0], \n",
    "    'History' : [0],\n",
    "    'Horror' : [0],\n",
    "    'Music' : [0], \n",
    "    'Musical' : [0],\n",
    "    'Mystery' : [0],\n",
    "    'News' : [0],\n",
    "    'Romance' : [0], \n",
    "    'Sci-Fi' : [0],\n",
    "    'Short' : [0], \n",
    "    'Sport' : [0],\n",
    "    'Thriller' : [0],\n",
    "    'War' : [0],\n",
    "    'Western' : [0],\n",
    "    'Approved' : [0],\n",
    "    'G' : [0],\n",
    "    'GP' : [0],\n",
    "    'M' : [0],\n",
    "    'NC-17' : [0], \n",
    "    'Not Rated' : [0],\n",
    "    'PG' : [0],\n",
    "    'PG-13' : [0],\n",
    "    'Passed' : [0],\n",
    "    'R' : [0],\n",
    "    'TV-14' : [0],\n",
    "    'TV-G' : [0],\n",
    "    'TV-PG' : [1],\n",
    "    'Unrated' : [0],\n",
    "    'X' : [0],\n",
    "    'director_experience' : [50]\n",
    "    }\n",
    "\n",
    "\n",
    "single = pd.DataFrame(input)\n",
    "StandardScaler().fit_transform(single)\n",
    "single = scaler.transform(single)\n",
    "prediction = model.predict(single)\n",
    "print(f\"Predicted IMDb Score: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dummies.columns.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
