{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV into a DataFrame\n",
    "imdb_df = pd.read_csv('../../resources/movie_metadata.csv')\n",
    "\n",
    "# print all columns\n",
    "for column in imdb_df.columns:\n",
    "    print(column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove specific columns\n",
    "columns_to_remove = ['aspect_ratio', 'movie_facebook_likes', 'movie_imdb_link', 'facenumber_in_poster']\n",
    "imdb_df = imdb_df.drop(columns=columns_to_remove)\n",
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.info()\n",
    "imdb_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame with numeric columns\n",
    "imdb_df_numeric = imdb_df.select_dtypes(include='number')\n",
    "\n",
    "# Find correlation between numeric columns with imdb_score\n",
    "correlation = imdb_df_numeric.corr()['imdb_score'].sort_values(ascending=False)\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = imdb_df_numeric.isnull().sum().sort_values(ascending=False)\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns for which you want to remove null values\n",
    "columns_to_clean = ['color', 'num_critic_for_reviews', 'duration', 'director_facebook_likes', \n",
    "                    'actor_3_facebook_likes', 'actor_1_facebook_likes', 'plot_keywords', \n",
    "                    'language', 'content_rating', 'actor_2_facebook_likes']\n",
    "\n",
    "# Remove rows where any of these columns have null values\n",
    "imdb_df = imdb_df.dropna(subset=columns_to_clean)\n",
    "\n",
    "# Reset the index after dropping rows\n",
    "imdb_df_clean = imdb_df.reset_index(drop=True)\n",
    "\n",
    "# Display the new shape of the DataFrame\n",
    "print(f\"DataFrame shape after removing additional nulls: {imdb_df.shape}\")\n",
    "\n",
    "# Check for missing values in the cleaned DataFrame\n",
    "print(imdb_df.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.info()\n",
    "imdb_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where either 'gross' or 'budget' is null\n",
    "imdb_df_clean = imdb_df.dropna(subset=['gross', 'budget'])\n",
    "\n",
    "# Reset the index after dropping rows\n",
    "imdb_df_clean = imdb_df_clean.reset_index(drop=True)\n",
    "\n",
    "# Display the new shape of the DataFrame\n",
    "print(f\"Original DataFrame shape: {imdb_df.shape}\")\n",
    "print(f\"Cleaned DataFrame shape: {imdb_df_clean.shape}\")\n",
    "missing_values_clean = imdb_df_clean.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Replacing null values with a placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a placeholder for missing values\n",
    "PLACEHOLDER = 'Unknown'\n",
    "\n",
    "# Replace NaN with the placeholder for actor name columns\n",
    "for col in ['actor_1_name', 'actor_2_name', 'actor_3_name']:\n",
    "    imdb_df_clean[col] = imdb_df_clean[col].fillna(PLACEHOLDER)\n",
    "\n",
    "# Verify the changes\n",
    "print(imdb_df_clean[['actor_1_name', 'actor_2_name', 'actor_3_name']].head(10))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preserve the original names for identification and further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store original actor names in new columns\n",
    "imdb_df_clean['original_actor_1_name'] = imdb_df_clean['actor_1_name']\n",
    "imdb_df_clean['original_actor_2_name'] = imdb_df_clean['actor_2_name']\n",
    "imdb_df_clean['original_actor_3_name'] = imdb_df_clean['actor_3_name']\n",
    "imdb_df_clean['original_director_name'] = imdb_df_clean['director_name']\n",
    "#imdb_df.head()\n",
    "print(imdb_df_clean[['original_actor_1_name', 'original_actor_2_name', 'original_actor_3_name', 'original_director_name']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Encoding (map these mean scores back to the respective actor columns in the original DataFrame).\n",
    "The encoded actor columns can now serve as features, where the actor names are replaced by their corresponding mean IMDb score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess names\n",
    "columns_to_preprocess = ['actor_1_name', 'actor_2_name', 'actor_3_name', 'director_name']\n",
    "for col in columns_to_preprocess:\n",
    "    imdb_df_clean[col] = imdb_df_clean[col].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Create Actor and Director Mean Mapping\n",
    "melted_df = imdb_df_clean.melt(\n",
    "    id_vars=['imdb_score'], \n",
    "    value_vars=columns_to_preprocess, \n",
    "    value_name='act_dir'\n",
    ")\n",
    "melted_df['act_dir'] = melted_df['act_dir'].astype(str).str.strip().str.lower()\n",
    "person_mean_mapping = melted_df.groupby('act_dir')['imdb_score'].mean()\n",
    "\n",
    "# Apply Target Encoding\n",
    "for col in columns_to_preprocess:\n",
    "    imdb_df_clean[col] = imdb_df_clean[col].map(person_mean_mapping).fillna(imdb_df_clean['imdb_score'].mean())\n",
    "\n",
    "# Example: Get mean IMDb score for a specific actor\n",
    "tom_cruise_score = person_mean_mapping.get('tom cruise', None)\n",
    "print(f\"Mean IMDb Score for Tom Cruise: {tom_cruise_score}\")\n",
    "\n",
    "# Verify the DataFrame\n",
    "print(imdb_df_clean[['original_actor_1_name', 'original_actor_2_name', 'original_actor_3_name', 'original_director_name', \n",
    "               'actor_1_name', 'actor_2_name', 'actor_3_name', 'director_name']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features as all columns in imdb_df_clean\n",
    "features = imdb_df_clean.columns\n",
    "\n",
    "# Check for missing values in all features\n",
    "print(imdb_df_clean[features].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "features = ['num_voted_users', 'num_critic_for_reviews', 'num_user_for_reviews', \n",
    "            'duration', 'gross', 'director_facebook_likes', 'cast_total_facebook_likes',\n",
    "            'actor_1_facebook_likes', 'actor_2_facebook_likes', 'actor_3_facebook_likes',\n",
    "            'budget', 'title_year', 'actor_1_name', 'actor_2_name', 'actor_3_name', 'director_name']\n",
    "\n",
    "X = imdb_df_clean[features]\n",
    "y = imdb_df_clean['imdb_score']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Lasso Regression\": Lasso(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"SVR\": SVR()\n",
    "}\n",
    "\n",
    "# Function to evaluate model\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mse, r2\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    mse, r2 = evaluate_model(model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    results[name] = {\"MSE\": mse, \"R2\": r2}\n",
    "\n",
    "# Print results\n",
    "print(\"Model Performance:\")\n",
    "for model, metrics in results.items():\n",
    "    print(f\"{model}:\")\n",
    "    print(f\"  MSE: {metrics['MSE']:.4f}\")\n",
    "    print(f\"  R2 Score: {metrics['R2']:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Feature importance for Random Forest if used\n",
    "if \"Random Forest\" in models:\n",
    "    rf_model = models[\"Random Forest\"]\n",
    "    rf_model.fit(X_train_scaled, y_train)\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'importance': rf_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    print(\"Feature Importance (Random Forest):\")\n",
    "    print(feature_importance)\n",
    "\n",
    "\n",
    "# PCA for feature reduction\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(f\"Number of components to explain 95% variance: {pca.n_components_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models and their performance metrics\n",
    "models = ['Linear Regression', 'Ridge Regression', 'Lasso Regression', 'Random Forest', 'Gradient Boosting', 'SVR']\n",
    "mse_scores = [0.2387, 0.2387, 0.9286, 0.2267, 0.2241, 0.2061]\n",
    "r2_scores = [0.7423, 0.7424, -0.0022, 0.7553, 0.7581, 0.7776]\n",
    "\n",
    "# Set up the figure and axes\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot MSE\n",
    "bars = ax1.bar(models, mse_scores)\n",
    "ax1.set_title('Mean Squared Error (MSE) by Model')\n",
    "ax1.set_ylabel('MSE')\n",
    "ax1.set_xlabel('Model')\n",
    "ax1.set_ylim(0, max(mse_scores) * 1.1)  # Adjust y-axis limit for better visibility\n",
    "\n",
    "# Angle the x-axis labels for MSE plot\n",
    "ax1.set_xticklabels(models, rotation=45, ha='right')\n",
    "\n",
    "# Plot R² Score\n",
    "bars = ax2.bar(models, r2_scores)\n",
    "ax2.set_title('R² Score by Model')\n",
    "ax2.set_ylabel('R² Score')\n",
    "ax2.set_xlabel('Model')\n",
    "ax2.set_ylim(min(r2_scores) - 0.05, 1)  # Adjust y-axis limit for better visibility\n",
    "\n",
    "# Angle the x-axis labels for R² Score plot\n",
    "ax2.set_xticklabels(models, rotation=45, ha='right')\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where gross is null or zero to avoid log issues\n",
    "filtered_df = imdb_df_clean[imdb_df_clean['gross'] > 0]\n",
    "\n",
    "# Log transform gross for better visualization of the relationship\n",
    "filtered_df['gross_rev'] = np.log1p(filtered_df['gross'])\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(filtered_df['gross_rev'], filtered_df['imdb_score'], alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Gross Revenue')\n",
    "plt.ylabel('IMDB Score')\n",
    "plt.title('Relationship between Gross Revenue and IMDB Score')\n",
    "\n",
    "# Add a trend line\n",
    "z = np.polyfit(filtered_df['gross_rev'], filtered_df['imdb_score'], 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(filtered_df['gross_rev'], p(filtered_df['gross_rev']), \"r--\")\n",
    "\n",
    "# Add grid for better readability\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the hexbin plot\n",
    "hb = plt.hexbin(imdb_df_clean['director_name'], imdb_df_clean['imdb_score'], \n",
    "                gridsize=20, cmap='viridis', bins='log')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Number of movies directed (By Director)')\n",
    "plt.ylabel('IMDB Score')\n",
    "plt.title('Density of Movie Scores by Director Experience')\n",
    "\n",
    "# Add a color bar\n",
    "plt.colorbar(hb, label='Count of Movies')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Assuming your DataFrame is named imdb_df_clean\n",
    "# Filter out movies with zero or null gross to avoid issues with log transformation\n",
    "filtered_df = imdb_df_clean[imdb_df_clean['gross'] > 0]\n",
    "\n",
    "# Log transform gross for better visualization\n",
    "filtered_df['gross_rev'] = np.log1p(filtered_df['gross'])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create the scatter plot using seaborn for enhanced aesthetics\n",
    "sns.scatterplot(x='gross_rev', y='imdb_score', data=filtered_df, alpha=0.6)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Log(Gross Revenue)')\n",
    "plt.ylabel('IMDB Score')\n",
    "plt.title('IMDB Score vs Log(Gross Revenue)')\n",
    "\n",
    "# Add a trend line\n",
    "z = np.polyfit(filtered_df['gross_rev'], filtered_df['imdb_score'], 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(filtered_df['gross_rev'], p(filtered_df['gross_rev']), \"r--\", label='Trend Line')\n",
    "\n",
    "# Add grid for better readability\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
