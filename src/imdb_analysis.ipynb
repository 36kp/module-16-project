{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.fetcher_utils as fetcher\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import utils.preprocess_util as preproc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data from the IMDb dataFrame\n",
    "imdb_df = fetcher.aquireIMDbDataFrame()\n",
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['movie_imdb_link','aspect_ratio', 'plot_keywords']\n",
    "\n",
    "imdb_df_filtered = imdb_df.drop(columns=drop_columns)\n",
    "imdb_df_filtered = imdb_df_filtered.dropna(subset='title_year')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_X_train_filtered = imdb_df_filtered[sorted(imdb_df_filtered.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df_filtered = imdb_df_filtered[(imdb_df_filtered['gross']>1_000) & \n",
    "                                    (imdb_df_filtered['budget']>1_000) & \n",
    "                                    (imdb_df_filtered['country'] == 'USA') &\n",
    "                                    (imdb_df['title_year']>1994)].drop(columns='country').reset_index(drop=True)\n",
    "imdb_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imdb_df_filtered.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imdb_df_filtered.drop(columns=['imdb_score'])\n",
    "y = imdb_df_filtered['imdb_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1\n",
    "\n",
    "for df in [X_train, X_test]:\n",
    "\n",
    "       df = preproc._director_frequence(df)\n",
    "       df = preproc._process_genres(df)\n",
    "\n",
    "       content_rating_replaced_df = preproc._bucket_contentRatings(df)\n",
    "\n",
    "       if counter == 1:\n",
    "              print('1')\n",
    "              encoder = OneHotEncoder(sparse_output=False)  \n",
    "              content_rating_encoded = encoder.fit_transform(content_rating_replaced_df[[\"rating_bin\"]])\n",
    "              content_rating_encoded = pd.DataFrame(content_rating_encoded, columns=encoder.get_feature_names_out([\"rating_bin\"]))\n",
    "              content_rating_encoded\n",
    "\n",
    "       else:\n",
    "              print('2')\n",
    "              content_rating_encoded = encoder.transform(content_rating_replaced_df[[\"rating_bin\"]])\n",
    "              content_rating_encoded = pd.DataFrame(content_rating_encoded, columns=encoder.get_feature_names_out([\"rating_bin\"]))\n",
    "              content_rating_encoded\n",
    "\n",
    "        \n",
    "\n",
    "       df = pd.concat([df.reset_index(drop=True), content_rating_encoded], axis=1)\n",
    "       # df.drop('content_rating', axis=1, inplace=True)\n",
    "\n",
    "       df = preproc._actor_frequency(df)\n",
    "\n",
    "       df['total_facebook_likes'] = df['actor_1_facebook_likes'] + df['actor_2_facebook_likes'] + df['actor_3_facebook_likes']\n",
    "\n",
    "       drop_columns = ['actor_1_facebook_likes', 'actor_2_facebook_likes','actor_3_facebook_likes','color','language','movie_title']\n",
    "       df = df.drop(columns=drop_columns)\n",
    "\n",
    "\n",
    "       columns_to_standardize = ['num_critic_for_reviews', 'duration', 'director_facebook_likes',\n",
    "              'gross', 'num_voted_users', 'cast_total_facebook_likes',\n",
    "              'facenumber_in_poster', 'num_user_for_reviews', 'budget', 'title_year',\n",
    "              'movie_facebook_likes', 'director_frequency', 'total_actor_frequency',\n",
    "              'total_facebook_likes']\n",
    "\n",
    "\n",
    "       scaler = StandardScaler()\n",
    "\n",
    "       # Fit the scaler to the training data\n",
    "       scaler.fit(df[columns_to_standardize])\n",
    "\n",
    "       # Scale the training features\n",
    "       scaled_features = scaler.transform(df[columns_to_standardize])\n",
    "\n",
    "       # Create a DataFrame with the scaled features\n",
    "       scaled_df = pd.DataFrame(scaled_features, columns=columns_to_standardize)\n",
    "\n",
    "       df = pd.concat([df.drop(columns=columns_to_standardize), scaled_df], axis=1)\n",
    "\n",
    "       df = df.fillna(-1)\n",
    "\n",
    "       if counter == 1:\n",
    "              X_train = df[sorted(df.columns)]\n",
    "       else:\n",
    "              X_test = df[sorted(df.columns)]\n",
    "       \n",
    "       counter += 1\n",
    "\n",
    "       print(sorted(df.columns))\n",
    "\n",
    "       display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test =  X_test.drop(columns='Mystery')\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_test = pd.concat([X_train, y_train.reset_index(drop=True)], axis=1)\n",
    "corr_test.corr()['imdb_score'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate VIF\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calc_vif(X):\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_vif(X_train).sort_values(\"VIF\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filtered = X_train.drop(columns=['cast_total_facebook_likes', 'rating_bin_R'])\n",
    "X_test_filtered = X_test.drop(columns=['cast_total_facebook_likes', 'rating_bin_R'])\n",
    "calc_vif(X_train_filtered).sort_values(\"VIF\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Use the statsmodels package to create and fit a linear regression\n",
    "lr = sm.OLS(y_train.reset_index(drop=True), X_train_filtered).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable to hold the p-values of all columns sorted in ascending order\n",
    "p_values = lr.pvalues.sort_values(ascending=False)\n",
    "p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use loc to filter to columns with p-values below 0.05\n",
    "select_cols = p_values.loc[p_values < 0.05]\n",
    "\n",
    "# Show the index of the results\n",
    "select_cols.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(select_cols.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filtered=X_train_filtered[select_cols.index]\n",
    "X_train_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_filtered=X_test_filtered[select_cols.index]\n",
    "X_test_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Create and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_filtered, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_filtered)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Create and train a lasso regression model\n",
    "lasso_model = Lasso(alpha=1)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Create predictions with the model\n",
    "y_predicted_lasso = lasso_model.predict(X_test)\n",
    "\n",
    "print(mean_squared_error(y_test, y_predicted_lasso))\n",
    "# print(r2_score(y_test, y_predicted_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Ridge\n",
    "model_cv = RidgeCV(alphas=[0.001, 0.01, 0.1, 1, 10])\n",
    "model_cv = model_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the alpha of the best model\n",
    "model_cv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model using the best alpha\n",
    "model2 = Ridge(alpha=model_cv.alpha_)\n",
    "\n",
    "# Train the model\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Create predictions and calculate the mean squared error\n",
    "y_predicted2 = model2.predict(X_test)\n",
    "mean_squared_error(y_test, y_predicted2)\n",
    "print(r2_score(y_test, y_predicted2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 7))\n",
    "\n",
    "# Plot the histogram on the first subplot\n",
    "ax1.hist(imdb_df_filtered['imdb_score'], bins=10, edgecolor='black')\n",
    "ax1.set_title('Histogram')\n",
    "ax1.set_xlabel('IMDB score')\n",
    "ax1.set_ylabel('Frequency')\n",
    "\n",
    "# Plot the boxplot on the second subplot\n",
    "ax2.boxplot(imdb_df_filtered['imdb_score'])\n",
    "ax2.set_title('Boxplot')\n",
    "ax2.set_ylabel('IMDB score')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot the histogram on the first subplot\n",
    "ax1.hist(imdb_df_filtered['gross'], bins=100, edgecolor='black')\n",
    "ax1.set_title('Histogram')\n",
    "ax1.set_xlabel('Gross')\n",
    "ax1.set_ylabel('Frequency')\n",
    "\n",
    "# Plot the histogram on the first subplot\n",
    "ax2.hist(imdb_df_filtered['budget'], bins=30, edgecolor='black')\n",
    "ax2.set_title('Histogram')\n",
    "ax2.set_xlabel('Budget')\n",
    "ax2.set_ylabel('Frequency')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
